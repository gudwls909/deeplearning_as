{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence GAN from char-rnn\n",
    "This is a character-level language model using recurrent neural networks based Sequence GAN (SeqGAN).\n",
    "SeqGAN was proposed to cover discrete sequence data.\n",
    "In this assignment, you will implement SeqGAN with shakespeare data used in assignment 3.\n",
    "\n",
    "Original blog post & code:\n",
    "https://github.com/LantaoYu/SeqGAN\n",
    "\n",
    "That said, you are allowed to copy paste the codes from the original repo with an additional effort to apply it to our data.\n",
    "HOWEVER, try to implement the model yourself first, and consider the original source code as a last resort.\n",
    "You will learn a lot while wrapping around your head during the implementation. And you will understand more clearly in a code level.\n",
    "\n",
    "### AND MOST IMPORTANTLY, IF YOU JUST BLINDLY COPY PASTE THE CODE, YOU SHALL RUIN YOUR EXAM.\n",
    "### The exam is designed to be solvable for students that actually have written the code themselves.\n",
    "At least strictly re-type the codes from the original repo line-by-line, and understand what each line means thoroughly.\n",
    "\n",
    "## YOU HAVE BEEN WARNED.\n",
    "\n",
    "Now proceed to the code. You may use textloader in previous assingment or not. You can freely create another python files (\\*.py) and then import them. Following codes can be modified as you want. Just make sure that SeqGAN training works.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "# ipython magic function for limiting the gpu to be seen for tensorflow\n",
    "# if you have just 1 GPU, specify the value to 0\n",
    "# if you have multiple GPUs (nut) and want to specify which GPU to use, specify this value to 0 or 1 or etc.\n",
    "%env CUDA_DEVICE_ORDER = PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES = 2\n",
    "# load a bunch of libraries\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.contrib import legacy_seq2seq\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "from six.moves import cPickle\n",
    "from six import text_type\n",
    "import sys\n",
    "\n",
    "# this module is from the .py file of this folder\n",
    "# it handles loading texts to digits (aka. tokens) which are recognizable for the model\n",
    "from utils import TextLoader\n",
    "\n",
    "# for TensorFlow vram efficiency: if this is not specified, the model hogs all the VRAM even if it's not necessary\n",
    "# bad & greedy TF! but it has a reason for this design choice FWIW, try googling it if interested\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "data_dir = 'data/tinyshakespeare'\n",
    "seq_length = 20\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, 'e': 1, 't': 2, 'o': 3, 'a': 4, 'h': 5, 's': 6, 'r': 7, 'n': 8, 'i': 9, '\\n': 10, 'l': 11, 'd': 12, 'u': 13, 'm': 14, 'y': 15, ',': 16, 'w': 17, 'f': 18, 'c': 19, 'g': 20, 'I': 21, 'b': 22, 'p': 23, ':': 24, '.': 25, 'A': 26, 'v': 27, 'k': 28, 'T': 29, \"'\": 30, 'E': 31, 'O': 32, 'N': 33, 'R': 34, 'S': 35, 'L': 36, 'C': 37, ';': 38, 'W': 39, 'U': 40, 'H': 41, 'M': 42, 'B': 43, '?': 44, 'G': 45, '!': 46, 'D': 47, '-': 48, 'F': 49, 'Y': 50, 'P': 51, 'K': 52, 'V': 53, 'j': 54, 'q': 55, 'x': 56, 'z': 57, 'J': 58, 'Q': 59, 'Z': 60, 'X': 61, '3': 62, '&': 63, '$': 64}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "with open(os.path.join('./data/tinyshakespeare/', 'vocab.pkl'), 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "idx_to_vocab = dict()\n",
    "for i in range(len(vocab)):\n",
    "    idx_to_vocab[vocab[i]] = i\n",
    "print(idx_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 9, 7, 6, 2, 0, 37, 9, 2, 9, 57, 1, 8, 24, 10, 43, 1, 18, 3, 7, 1, 0, 17, 1, 0, 23, 7, 3, 19, 1, 1, 12, 0, 4, 8, 15, 0, 18, 13, 7, 2, 5, 1, 7, 16, 0, 5, 1, 4, 7, 0, 14, 1, 0, 6, 23, 1, 4, 28, 25, 10]\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('./data/tinyshakespeare/', 'input.txt'), 'rb') as f:\n",
    "    lines = f.readlines()\n",
    "    l = list()\n",
    "    temp = list()\n",
    "    for line in lines:\n",
    "        if len(line)==1:\n",
    "            for i in range(len(temp)):\n",
    "                temp[i] = list(temp[i].decode('UTF-8'))\n",
    "                #temp[i] = temp[i][:-1]\n",
    "                for j in range(len(temp[i])):\n",
    "                    temp[i][j] = idx_to_vocab[temp[i][j]]\n",
    "                    \n",
    "            l.append(sum(temp,[]))\n",
    "            temp = list()\n",
    "        else:\n",
    "            temp.append(line)\n",
    "\n",
    "print(l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0793435   0.19020333  0.0922966   0.08004362  0.20611638  0.10598402\n",
      " -0.02360283  0.0163842   0.13102228 -0.02654421  0.11638848 -0.0094324\n",
      "  0.00747876 -0.07338662 -0.15279333  0.19423566  0.07700936 -0.03131523\n",
      " -0.15540833  0.0645715   0.14683448 -0.00246805 -0.03904026 -0.24221624\n",
      "  0.04898092  0.09916815 -0.19150893  0.17427377  0.04934009 -0.14824519\n",
      "  0.02098398 -0.06480274]\n"
     ]
    }
   ],
   "source": [
    "emb = list()\n",
    "for _ in range(65):\n",
    "    emb.append(np.random.normal(0, 0.1, 32))\n",
    "    \n",
    "embedding = dict()\n",
    "for i in range(len(emb)):\n",
    "    embedding[i] = emb[i]\n",
    "print(embedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0793435   0.19020333  0.0922966   0.08004362  0.20611638  0.10598402\n",
      " -0.02360283  0.0163842   0.13102228 -0.02654421  0.11638848 -0.0094324\n",
      "  0.00747876 -0.07338662 -0.15279333  0.19423566  0.07700936 -0.03131523\n",
      " -0.15540833  0.0645715   0.14683448 -0.00246805 -0.03904026 -0.24221624\n",
      "  0.04898092  0.09916815 -0.19150893  0.17427377  0.04934009 -0.14824519\n",
      "  0.02098398 -0.06480274]\n"
     ]
    }
   ],
   "source": [
    "l_emb = list()\n",
    "for i in range(len(l)):\n",
    "    l_emb.append(list())\n",
    "    \n",
    "for i in range(len(l)):\n",
    "    for j in range(len(l[i])):\n",
    "        l_emb[i].append(embedding[l[i][j]])\n",
    "\n",
    "print(l_emb[0][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "(5000, 32)\n",
      "(32, 32)\n",
      "(32, 32)\n",
      "(32,)\n",
      "(32, 32)\n",
      "(32, 32)\n",
      "(32,)\n",
      "(32, 32)\n",
      "(32, 32)\n",
      "(32,)\n",
      "(32, 32)\n",
      "(32, 32)\n",
      "(32,)\n",
      "(32, 5000)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('./save/', 'target_params_py3.pkl'), 'rb') as f:\n",
    "    target_params = pickle.load(f)\n",
    "print(len(target_params))\n",
    "for i in range(len(target_params)):\n",
    "    print(target_params[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
